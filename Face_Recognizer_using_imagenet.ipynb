{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Face_Recognizer_using_imagenet.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyObSuOwQ/Ni08hVkASSBCgk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sayan0506/Real-Time-Face-Recognition-Using-Siamese-Network-with-Triplet-Loss-in-Keras/blob/master/Face_Recognizer_using_imagenet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHlE_MUBb8BW",
        "outputId": "4b56d127-a1fb-4ac1-e93d-591fbe5c0fad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        }
      },
      "source": [
        "'''Face Recognition Main File\n",
        "import cv2\n",
        "import numpy as np\n",
        "import glob\n",
        "from scipy.spatial import distance\n",
        "from imutils import face_utils\n",
        "from keras.models import load_model\n",
        "import tensorflow as tf\n",
        "\n",
        "from fr_utils import *\n",
        "from inception_blocks_v2 import *\n",
        "\n",
        "#with CustomObjectScope({'tf': tf}):\n",
        "FR_model = load_model('nn4.small2.v1.h5')\n",
        "print(\"Total Params:\", FR_model.count_params())\n",
        "\n",
        "face_cascade = cv2.CascadeClassifier('haarcascades/haarcascade_frontalface_default.xml')\n",
        "\n",
        "threshold = 0.25\n",
        "\n",
        "face_database = {}\n",
        "\n",
        "for name in os.listdir('images'):\n",
        "\tfor image in os.listdir(os.path.join('images',name)):\n",
        "\t\tidentity = os.path.splitext(os.path.basename(image))[0]\n",
        "\t\tface_database[identity] = fr_utils.img_path_to_encoding(os.path.join('images',name,image), FR_model)\n",
        "\n",
        "print(face_database)\n",
        "\n",
        "video_capture = cv2.VideoCapture(0)\n",
        "while True:\n",
        "\tret, frame = video_capture.read()\n",
        "\tframe = cv2.flip(frame, 1)\n",
        "\n",
        "\tfaces = face_cascade.detectMultiScale(frame, 1.3, 5)\n",
        "\tfor(x,y,w,h) in faces:\n",
        "\t\tcv2.rectangle(frame, (x, y), (x + w, y + h), (255, 255, 0), 2)\n",
        "\t\troi = frame[y:y+h, x:x+w]\n",
        "\t\tencoding = img_to_encoding(roi, FR_model)\n",
        "\t\tmin_dist = 100\n",
        "\t\tidentity = None\n",
        "\n",
        "\t\tfor(name, encoded_image_name) in face_database.items():\n",
        "\t\t\tdist = np.linalg.norm(encoding - encoded_image_name)\n",
        "\t\t\tif(dist < min_dist):\n",
        "\t\t\t\tmin_dist = dist\n",
        "\t\t\t\tidentity = name\n",
        "\t\t\tprint('Min dist: ',min_dist)\n",
        "\n",
        "\t\tif min_dist < 0.1:\n",
        "\t\t\tcv2.putText(frame, \"Face : \" + identity[:-1], (x, y - 50), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), 2)\n",
        "\t\t\tcv2.putText(frame, \"Dist : \" + str(min_dist), (x, y - 20), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), 2)\n",
        "\t\telse:\n",
        "\t\t\tcv2.putText(frame, 'No matching faces', (x, y - 20), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 0, 255), 2)\n",
        "\n",
        "\tcv2.imshow('Face Recognition System', frame)\n",
        "\tif(cv2.waitKey(1) & 0xFF == ord('q')):\n",
        "\t\tbreak\n",
        "\n",
        "video_capture.release()\n",
        "cv2.destroyAllWindows()\n",
        "'''"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Face Recognition Main File\\nimport cv2\\nimport numpy as np\\nimport glob\\nfrom scipy.spatial import distance\\nfrom imutils import face_utils\\nfrom keras.models import load_model\\nimport tensorflow as tf\\n\\nfrom fr_utils import *\\nfrom inception_blocks_v2 import *\\n\\n#with CustomObjectScope({\\'tf\\': tf}):\\nFR_model = load_model(\\'nn4.small2.v1.h5\\')\\nprint(\"Total Params:\", FR_model.count_params())\\n\\nface_cascade = cv2.CascadeClassifier(\\'haarcascades/haarcascade_frontalface_default.xml\\')\\n\\nthreshold = 0.25\\n\\nface_database = {}\\n\\nfor name in os.listdir(\\'images\\'):\\n\\tfor image in os.listdir(os.path.join(\\'images\\',name)):\\n\\t\\tidentity = os.path.splitext(os.path.basename(image))[0]\\n\\t\\tface_database[identity] = fr_utils.img_path_to_encoding(os.path.join(\\'images\\',name,image), FR_model)\\n\\nprint(face_database)\\n\\nvideo_capture = cv2.VideoCapture(0)\\nwhile True:\\n\\tret, frame = video_capture.read()\\n\\tframe = cv2.flip(frame, 1)\\n\\n\\tfaces = face_cascade.detectMultiScale(frame, 1.3, 5)\\n\\tfor(x,y,w,h) in faces:\\n\\t\\tcv2.rectangle(frame, (x, y), (x + w, y + h), (255, 255, 0), 2)\\n\\t\\troi = frame[y:y+h, x:x+w]\\n\\t\\tencoding = img_to_encoding(roi, FR_model)\\n\\t\\tmin_dist = 100\\n\\t\\tidentity = None\\n\\n\\t\\tfor(name, encoded_image_name) in face_database.items():\\n\\t\\t\\tdist = np.linalg.norm(encoding - encoded_image_name)\\n\\t\\t\\tif(dist < min_dist):\\n\\t\\t\\t\\tmin_dist = dist\\n\\t\\t\\t\\tidentity = name\\n\\t\\t\\tprint(\\'Min dist: \\',min_dist)\\n\\n\\t\\tif min_dist < 0.1:\\n\\t\\t\\tcv2.putText(frame, \"Face : \" + identity[:-1], (x, y - 50), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), 2)\\n\\t\\t\\tcv2.putText(frame, \"Dist : \" + str(min_dist), (x, y - 20), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), 2)\\n\\t\\telse:\\n\\t\\t\\tcv2.putText(frame, \\'No matching faces\\', (x, y - 20), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 0, 255), 2)\\n\\n\\tcv2.imshow(\\'Face Recognition System\\', frame)\\n\\tif(cv2.waitKey(1) & 0xFF == ord(\\'q\\')):\\n\\t\\tbreak\\n\\nvideo_capture.release()\\ncv2.destroyAllWindows()\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60y4a_-zcZ7c",
        "outputId": "6f5d4e81-84cd-4edd-e064-3eec4a6ec501",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        " from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgtyPHS_GsmS",
        "outputId": "f0e281ef-1bf0-40bc-948f-74416d6efca7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!ls /content/gdrive/My\\ Drive/*.py"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'/content/gdrive/My Drive/prediction_of_image.py'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75wB_h5BG8EU"
      },
      "source": [
        "import sys"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8riSlOqBHGjM"
      },
      "source": [
        "sys.path.append('/content/gdrive/MyDrive/Face-Recognition-master')"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9vugGLXHPHM"
      },
      "source": [
        "import fr_utils"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_ilngG_HUoe"
      },
      "source": [
        "from keras import backend as K\n",
        "import time\n",
        "from multiprocessing.dummy import Pool\n",
        "K.set_image_data_format('channels_first')\n",
        "import cv2\n",
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "from numpy import genfromtxt\n",
        "import tensorflow as tf\n",
        "from fr_utils import *\n",
        "from inception_network import *\n",
        "# from face_functions import *\n",
        "from keras.models import load_model\n",
        "import sys \n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgN7ZFLUIHfR"
      },
      "source": [
        "def triplet_loss_function(y_true,y_pred,alpha = 0.3):\n",
        "\tanchor = y_pred[0]\n",
        "\tpositive = y_pred[1]\n",
        "\tnegative = y_pred[2]\n",
        "\tpos_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, positive)), axis=-1)\n",
        "\tneg_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, negative)), axis=-1)\n",
        "\tbasic_loss = tf.add(tf.subtract(pos_dist, neg_dist), alpha)\n",
        "\tloss = tf.reduce_sum(tf.maximum(basic_loss, 0.0))\n",
        "\treturn loss"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mymqktnUHe29"
      },
      "source": [
        "\n",
        "model = model(input_shape = (3,96,96))\n",
        "model.compile(optimizer = 'adam', loss = triplet_loss_function, metrics = ['accuracy'])"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IVzciNFIDN1"
      },
      "source": [
        "load_weights_from_FaceNet(model)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tq5pqxpXIrr8",
        "outputId": "85a15818-0752-43a0-e9df-5c282500cec7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIaGt_u8K0hH",
        "outputId": "e94774fc-9a45-4242-8f4a-383d3880ffb7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%cd /content/gdrive/MyDrive/Face-Recognition-master"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/Face-Recognition-master\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aa5mpkuJLDgF",
        "outputId": "a1e38e5d-7b47-42e6-83f0-01512b04c097",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "pwd"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/gdrive/MyDrive/Face-Recognition-master'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LF8UnU-8LFGF"
      },
      "source": [
        "model.save_weights(filepath = '/content/gdrive/MyDrive/Face-Recognition-master')"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mR3mtDOMQKt"
      },
      "source": [
        "# model.summary()"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxbL7eIfMf_-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}